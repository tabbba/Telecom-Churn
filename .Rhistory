group_by(International.plan, Churn) %>%
summarise(Count = n(), .groups = "drop") %>%
ggplot(aes(x = International.plan, y = Count, fill = Churn)) +
geom_bar(stat = "identity", position = position_dodge(width = 0.9), color = 1) +
geom_text(aes(label = Count),
position = position_dodge(width = 0.9),
vjust = -0.5,
size = 3.5) +
labs(title = "Churn by International Plan", x = "International Plan", y = "Count", fill = "Churn") +
theme_minimal()
# we see that more than half of the customers that have an international plan churned
cor_mat <-
data %>%
select(where(is.numeric)) %>%
cor()
corrplot(
main = "\n\nCorrelation Matrix",
cor_mat,
method = "color",
order = "alphabet",
type = "lower",
diag = FALSE,
number.cex = 0.8,
tl.cex = 0.6,
tl.srt = 45,
cl.pos = "b",
addgrid.col = "white",
addCoef.col = "white",
col = COL1("Purples"),
bg="gray",
tl.col = "grey50"
)
# with this plot we see that there is a perfect correlation between the charge variables and minutes variables
# so we can drop all the minutes one
# we drop Total.day.minutes, Total.eve.minutes, Total.night.minutes, Total.intl.minutes
data <- data %>%
select(-c(Total.day.minutes, Total.eve.minutes, Total.night.minutes, Total.intl.minutes))
group_plt <- function(var_1, var_2 = Churn){
for_title_1 <- as_label(enquo(var_1))
for_title_1 <- str_to_title(str_replace_all(for_title_1, "_", " "))
for_title_2 <- as_label(enquo(var_2))
for_title_2 <- str_to_title(str_replace_all(for_title_2, "_", " "))
data %>%
select({{var_1}}, {{var_2}}) %>%
mutate(var_1_ex = {{var_1}},
var_2_ex = {{var_2}}) %>%
count(var_1_ex, var_2_ex, name = "counts") %>%
mutate(perc = (counts / sum(counts)) * 100) %>%
arrange(desc(counts)) %>%
ggplot(aes("", counts)) +
geom_col(
position = "fill",
color = "black",
width = 1,
aes(fill = factor(var_2_ex))
) +
geom_text(
aes(label = str_c(round(perc,1), "%"),
group = factor(var_1_ex)),
position = position_fill(vjust = 0.5),
color = "white",
size = 5,
show.legend = FALSE,
fontface = "bold"
) +
coord_polar(theta = "y") +
scale_fill_manual (values = c("#193964", "#026AA3")) +
theme_void() +
facet_wrap(vars(str_c(var_1_ex, "\n", for_title_1)))+
labs(
title = glue(for_title_2, " proportion by ", for_title_1),
subtitle = " ",
fill =NULL
) +
theme(plot.title = element_text(hjust = 0.5),
legend.position = "bottom",
strip.text = element_text(
colour = "black",
size = 12,
face = "bold"
))
}
group_plt(Voice.mail.plan)
group_plt(International.plan)
group_plt(State)
ggplot(data, aes(x = State, fill = Churn)) +
geom_bar(width = 0.7, color = 1) +
theme_minimal() +
theme(axis.text.x = element_text(hjust = 0, colour = "gray29", size = 10)) +
labs(title = "Churn by State", x = "State", y = "Count", fill = "Churn", subtitle = "Is Churn rate influenced by State?") +
theme(
axis.text = element_blank(),
axis.title = element_blank(),
legend.position = "bottom",
plot.title = element_text(hjust = 0.5, face = "bold"),
plot.subtitle = element_text(hjust = 0.5)
) +
scale_y_continuous(limits = c(-35, 100)) +
scale_fill_manual(values = c("False" = "#ffe8cc", "True" = "#ff8787"), labels = c("False" = "No", "True" = "Yes")) +
coord_polar(start = 0)
us_map <- map_data("state") %>%
as_tibble()
us_map %>%
ggplot(aes(long, lat, map_id = region)) +
geom_map(
map =us_map,
color = "gray80",
fill = "gray30",
size = 0.3
) +
coord_map("ortho", orientation = c(39, -98, 0)) +
labs(
title = "US Map",
subtitle = "Based on Latitude and Longitude"
) + theme(plot.title = element_text(hjust=0.5))
state_names <- c(KS = "kansas", OH = "ohio", NJ = "new jersey", OK = "oklahoma",
AL = "alabama", MA = "massachusetts", MO = "missouri", LA = "louisiana",
WV = "west virginia", IN = "indiana", RI = "rhode island", IA = "iowa",
MT = "montana", NY = "new york", ID = "idaho", VT = "vermont",
VA = "virginia", TX = "texas", FL = "florida", CO = "colorado",
AZ = "arizona", SC = "south carolina", NE = "nebraska", WY = "wyoming",
HI = "hawaii", IL = "illinois", NH = "new hampshire", GA = "georgia",
AK = "alaska", MD = "maryland", AR = "arkansas", WI = "wisconsin",
OR = "oregon", MI = "michigan", DE = "delaware", UT = "utah",
CA = "california", MN = "minnesota", SD = "south dakota", NC = "north carolina",
WA = "washington", NM = "new mexico", NV = "nevada", DC = "district of columbia",
KY = "kentucky", ME = "maine", MS = "mississippi", TN = "tennessee",
PA = "pennsylvania", CT = "connecticut", ND = "north dakota")
churn.tbl <- data %>% select(State, Churn) %>%
group_by(State) %>%
summarize(
total_customers = n(),
churned_customers = sum(Churn == "True"),
churn_rate = (churned_customers / total_customers),
churn_rate_txt = scales::percent(churn_rate)
) %>%
mutate(full_state = state_names[as.character(State)]) %>%
ungroup() %>%
left_join(us_map, by=c("full_state" = "region"))
us_map_sf <- st_as_sf(us_map, coords = c("long", "lat"), crs = 4326, agr = "constant")
centroids <- us_map_sf %>%
group_by(region) %>%
summarise(geometry = st_centroid(st_union(geometry)))
centroids_df <- as.data.frame(st_coordinates(centroids))
centroids_df$region <- centroids$region
churn.tbl <- churn.tbl %>%
left_join(centroids_df, by = c("full_state" = "region"))
churn.tbl %>%
ggplot(aes(long, lat)) +
geom_map(
aes(map_id = full_state),
map = us_map,
color = "gray86",
fill = "gray30",
size = 0.3
) + coord_map("ortho", orientation = c(39, -98, 0)) + geom_polygon(aes(group = group, fill = churn_rate), color="black") +
scale_fill_gradient2("",low = "#18BC9C", mid = "white", high = "#E31A1C", midpoint = 0.10, labels = scales::percent) +
geom_text(aes(x = X, y = Y, label = State), stat = "unique", size = 3, inherit.aes = FALSE, fontface = "bold") +
theme_void() +
theme(
plot.title = element_text(size=18, face="bold", color = "#2C3E50"),
legend.position = "right"
) +
labs(
title = "Churn Rate Across US States",
x = "",
y = ""
) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
)
# Investigate the relationship between state and churn with a chi-squared test of independence
# H0: State and Churn are independent
# H1: State and Churn are dependent
contingency.table <- table(data$State, data$Churn)
chisq.test(contingency.table)
# p-value is significant, we reject the null hypothesis and conclude that state influences the churn rate
contingency.table <- table(data$Total.night.calls, data$Churn)
chisq.test(contingency.table)
# p-value is not significant, we fail to reject the null hypothesis and conclude that Total night calls does not influence the churn rate
#POINT 3
# Our task is to predict whether customers will churn or not. this task is useful for the company
# to take actions to prevent customers from churning.
# Moreover, it can helps the company to understand the reasons behind the churn and take actions to
# improve the service and customer satisfaction by offering also promotions to the customers that are more likely to churn.
# CONCLUSION UP TO NOW:
# we dropped the minutes variables because they are perfectly correlated with the charge variables
# we saw that the churn rate is higher for customers that have an international plan
# we saw that the churn rate is higher for customers that do not have a voice mail plan
# we saw that the churn rate is higher for customers that have a higher number of customer service calls
# we saw that the churn rate is higher for customers that have higher total day minutes and total day charge
# we saw that the churn rate is higher for customers that have higher total eve charge, night charge, and intl charge
# we saw that State also influences the churn rate
# POINT 4
# before proceeding with the full model we need to focus on some lower dimensional model in order to
# investigate some interesting relationships between the variables
# we'll proceed with customer service call and churn
# We only include customers who have made a service call
service_calls <- data %>%
filter(Customer.service.calls > 0)
# The proportion of customers who churned after making a service call:
churn_percent <- service_calls %>%
group_by(Customer.service.calls, Churn) %>%
summarise(Count = n(), .groups = "drop") %>%
mutate(Percent = Count / sum(Count) * 100)
ggplot(churn_percent, aes(x = Customer.service.calls, y = Percent, fill = Churn)) +
geom_col(width = 0.7, color = 1) +
labs(title = "Churn by Customer Service Calls", x = "Customer Service Calls", y = "Percent", fill = "Churn") +
theme_minimal() +
scale_fill_manual(values = c("False" = "#ffe8cc", "True" = "#ff8787"), labels = c("False" = "No", "True" = "Yes")) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
legend.position = "bottom"
)
set.seed(1)
data$Churn <- as.factor(data$Churn)
model <- glm(Churn ~ Customer.service.calls, family = binomial, data = data)
summary(model)
## the intercept's p-value (<2e-16) suggests that there is a statistically significant effect of having zero customer service calls on the likelihood of churn.
## the p-value for Customer.service.calls (<2e-16) suggests that there is a statistically significant association between the number of customer service calls and an increased likelihood of churn.
call_range <- seq(min(data$Customer.service.calls, na.rm = TRUE),
max(data$Customer.service.calls, na.rm = TRUE),
length.out = 100)
newdata <- data.frame(Customer.service.calls = call_range)
newdata$Probability <- predict(model, newdata = newdata, type = "response")
newdata$Odds <- newdata$Probability / (1 - newdata$Probability)
head(newdata)
# plotting the probability of churn based on customer service calls
ggplot(newdata, aes(x = Customer.service.calls, y = Probability)) +
geom_line() +
labs(title = "Effect of Customer Service Calls on the Probability of Churn",
x = "Number of Customer Service Calls",
y = "Probability of Churn") +
scale_y_continuous(labels = scales::percent_format()) +  # Convert y-axis into percentage format
theme_minimal() +  # Use a minimal theme
geom_hline(yintercept = 0.5, colour = "red", linetype = "dashed")
theme(
plot.title = element_text(hjust = 0.5),
axis.text.x = element_text(angle = 45, hjust = 1),
axis.title.x = element_text(face = "bold"),
axis.title.y = element_text(face = "bold")
)
# since we are dealing with an imbalanced dataset we undersample the majority class (no churn) to balance the dataset.
set.seed(1)
majority_indices <- which(data$Churn == 'False')
minority_count <- sum(data$Churn == 'True')
sampled_indices <- sample(majority_indices, size = minority_count, replace = FALSE)
balanced_data <- data[c(sampled_indices, which(data$Churn == 'True')), ]
levels(data$Churn)
balanced_data$Churn <- as.factor(balanced_data$Churn)
levels(balanced_data$Churn)
table(balanced_data$Churn)
balanced_model <- glm(Churn ~ Customer.service.calls, family = binomial, data = balanced_data )
summary(balanced_model)
# plot for balanced data
call_range <- seq(min(data$Customer.service.calls, na.rm = TRUE),
max(data$Customer.service.calls, na.rm = TRUE),
length.out = 100)
newdata <- data.frame(Customer.service.calls = call_range)
newdata$Probability <- predict(balanced_model, newdata = newdata, type = "response")
newdata$Odds <- newdata$Probability / (1 - newdata$Probability)
ggplot(newdata, aes(x = Customer.service.calls, y = Probability)) +
geom_line() +
labs(title = "Effect of Customer Service Calls on the Probability of Churn (Balanced Data)",
x = "Number of Customer Service Calls",
y = "Probability of Churn") +
scale_y_continuous(labels = scales::percent_format()) +  # Convert y-axis into percentage format
theme_minimal() +  # Use a minimal theme
theme(
plot.title = element_text(hjust = 0.5),
axis.text.x = element_text(angle = 45, hjust = 1),
axis.title.x = element_text(face = "bold"),
axis.title.y = element_text(face = "bold")
)
# plotting the confusion matrix for comparison
# 0 --> False, 1 --> True
# Prediction on the unbalanced data
confusion.mat <- function(data, model, target, threshold) {
predicted_Y <- ifelse(predict(model, type = "response", newdata = data) > threshold, 'True', 'False')
actual_Y <- data[[target]]
True.positive <- sum(predicted_Y == 'True' & actual_Y == 'True')
True.negative <- sum(predicted_Y == 'False' & actual_Y == 'False')
False.positive <- sum(predicted_Y == 'True' & actual_Y == 'False')
False.negative <- sum(predicted_Y == 'False' & actual_Y == 'True')
Confusion.Matrix <- matrix(c(True.positive, False.negative,
False.positive, True.negative),
nrow = 2, byrow = TRUE)
rownames(Confusion.Matrix) <- c("Actual Positive", "Actual Negative")
colnames(Confusion.Matrix) <- c("Predicted Positive", "Predicted Negative")
print(Confusion.Matrix)
}
confusion.mat(data, model, "Churn", 0.5) #Predictions on unbalanced data
confusion.mat(balanced_data,balanced_model, "Churn", 0.5) # Predictions on balanced data
## other interactions between different predictors:
### international plan and voice mail plan
set.seed(1)
data$Churn <- as.factor(data$Churn)
model <- glm(Churn ~ International.plan*Voice.mail.plan, family = binomial, data = data)
summary(model)
### Intercept: Very significant with a p-value < 2e-16, indicating a strong effect when both plans are absent.
### Both International.planYes and Voice.mail.planYes are highly significant
### Interaction term: while international plans are associated with higher churn, voice mail plans seem to mitigate churn risk.
### However, customers who have both plans are particularly at risk of churning, possibly due to the higher costs or complexities associated with managing multiple service features.
### Customer service call and international plan
set.seed(1)
data$Churn <- as.factor(data$Churn)
model <- glm(Churn ~ Customer.service.calls*International.plan, family = binomial, data = data)
summary(model)
### Both International.planYes and Customer.service.calls are highly significant
### Interaction term: customers with more customer service interactions generally have higher churn rates. However, the negative interaction indicates that
### the churn-increasing effect of service calls might be mitigated among customers with an international plan, possibly due to different expectations or experiences.
# POINT 5
# PREPROCESSING AND FEATURE ENGINEERING
# we should first deal with the 51 states, we can group them by region. let's do it
# let's group them by north, south, east, west
# print all the states
unique(data$State)
map_region <- function(state) {
west.regions <- c("WA", "OR", "ID", "MT", "WY", "CA", "NV", "UT", "CO", "AK", "HI")
southwest.regions <- c("AZ", "NM", "TX", "OK")
midwest.regions <- c("ND", "SD", "NE", "KS", "MN", "IA", "MO", "WI", "IL", "IN", "MI", "OH")
southeast.regions <- c("AR", "LA", "MS", "AL", "TN", "KY", "WV", "VA", "NC", "SC", "GA", "FL")
northeast.regions <- c("ME", "NH", "VT", "MA", "RI", "CT", "NY", "PA", "NJ", "DE", "MD", "DC")
if (state %in% west.regions) {
return("West")
} else if (state %in% midwest.regions) {
return("Mid West")
} else if (state %in% southeast.regions) {
return("South East")
} else if (state %in% northeast.regions) {
return("North East")
} else {
return("South West")  # in case there are any states not covered
}
}
data$Region <- sapply(data$State, map_region)
data$Region <- as.factor(data$Region)
# we'll use the regions column for the first models to avoid having high-cardinality encoded columns.
# we store the variable in order to use it later with more robust models (tree-based).
state.column <- data$State
data$State <- NULL
head(data)
# let's see the distribution of churn by region
group_plt(Region)
# now let's re-do the chi square
contingency.table <- table(data$Region, data$Churn)
chisq.test(contingency.table)
# H0: Region and Churn are independent
# H1: Region and Churn are dependent
#p-value > 0.05, we fail to reject the null hypothesis, therefore the region does not influence the churn rate
# let's see the distribution of churn by region
ggplot(data, aes(x = Region, fill = Churn)) +
geom_bar(width = 0.7, color = 1) +
theme_minimal() +
theme(axis.text.x = element_text(hjust = 0, colour = "gray29", size = 10)) +
labs(title = "Churn by Region", x = "Region", y = "Count", fill = "Churn", subtitle = "Is Churn rate influenced by the Region?") +
theme(
axis.text = element_blank(),
axis.title = element_blank(),
legend.position = "bottom",
plot.title = element_text(hjust = 0.5, face = "bold"),
plot.subtitle = element_text(hjust = 0.5)
) +
scale_fill_manual(values = c("False" = "#ffe8cc", "True" = "#ff8787"), labels = c("False" = "No", "True" = "Yes"))
# POINT 5
# data preprocessing
# - split the data into training and testing sets
# Set seed for reproducibility
set.seed(1)
ids.train <- sample(1:nrow(data), size = 0.75 * nrow(data), replace = FALSE)
data.train <- data[ids.train,]
data.val <- data[-ids.train,]
# Oversampling minority class
data.train.balanced <- ovun.sample(Churn ~ ., data = data.train, method = "over", N=4260)$data
table(data.train.balanced$Churn)
# SCALING
cols_to_scale <- c("Account.length", "Area.code", "Number.vmail.messages", "Total.day.calls", "Total.day.charge", "Total.eve.calls", "Total.eve.charge", "Total.night.calls", "Total.night.charge", "Total.intl.calls", "Total.intl.charge", "Customer.service.calls")
train.mean <- apply(data.train.balanced[, cols_to_scale], MARGIN = 2, FUN = mean)
train.sd <- apply(data.train.balanced[, cols_to_scale], MARGIN = 2, FUN = sd)
data.train.balanced[, cols_to_scale] <- scale(data.train.balanced[, cols_to_scale], center = train.mean, scale = train.sd)
# Scale validation data using training data's parameters
data.val[, cols_to_scale] <- scale(data.val[, cols_to_scale], center = train.mean, scale = train.sd)
# Baseline Logistic Regression Model
logistic.baseline <- glm(Churn ~ ., data = data.train.balanced, family = "binomial")
summary(logistic.baseline)
baseline.pred <- ifelse(predict(logistic.baseline, newdata = data.val) > 0.5, 1, 0)
(baseline.cm <- table(baseline.pred, data.val$Churn))
get.metrics<- function(conf.mat) {
true.positives <- conf.mat[2,2]
true.negatives <- conf.mat[1,1]
false.positives <- conf.mat[1,2]
false.negatives <- conf.mat[2,1]
num.observations <- true.positives + true.negatives + false.positives + false.negatives
accuracy <- (true.positives + true.negatives) / num.observations
precision <- (true.positives) / (true.positives + false.positives)
recall <- true.positives / (true.positives + false.negatives)
f1 <- 2 * ((precision * recall) / (precision + recall))
metrics <- data.frame(t(c(accuracy, precision, recall, f1)))
columns <- c("Accuracy", "Precision", "Recall", "F1")
colnames(metrics) <- columns
return(metrics)
}
(baseline.metrics <- get.metrics(baseline.cm))
akaike.fw <- step(glm(Churn ~ 1, family = "binomial", data = data.train.balanced), scope = formula(logistic.baseline), direction = "forward")
akaike.back <- step(logistic.baseline, direction = "backward")
akaike.both <- step(logistic.baseline, direction = "both")
bayesian.fw <- step(glm(Churn ~ 1, family = "binomial", data = data.train.balanced), scope = formula(logistic.baseline), direction = "forward", k = log(nrow(data.train.balanced)))
bayesian.back <- step(logistic.baseline, direction = "backward", k = log(nrow(data.train.balanced)))
bayesian.both <- step(logistic.baseline, direction = "both", k = log(nrow(data.train.balanced)))
# Validation set results
akaike.preds <- ifelse(predict(akaike.both, data.val) > 0.5, 1, 0)
(akaike.cm <- table(akaike.preds, data.val$Churn))
(akaike.metrics <- get.metrics(akaike.cm))
bayesian.preds <- ifelse(predict(bayesian.both, data.val) > 0.5, 1, 0)
(bayesian.cm <- table(bayesian.preds, data.val$Churn))
(bayesian.metrics <- get.metrics(bayesian.cm))
# Slightly better results with akaike, maybe dropping all the region features as BIC does is too big of a loss of informations
par(mfrow = c(2, 2))
roc_full <- roc(data.val$Churn, as.numeric(baseline.pred),
plot = TRUE, main = "ROC Curve Full Model", col = "purple", lwd = 3,
auc.polygon = TRUE, print.auc = TRUE)
roc_akaike <- roc(data.val$Churn, predict(akaike.both, newdata = data.val, type = "response"),
plot = TRUE, main = "AIC Model", col = "blue", lwd = 3,
auc.polygon = TRUE, print.auc = TRUE)
roc_bayesian <- roc(data.val$Churn, predict(bayesian.both, newdata = data.val, type = "response"),
plot = TRUE, main = "BIC Model", col = "red", lwd = 3,
auc.polygon = TRUE, print.auc = TRUE)
par(mfrow = c(1, 1))
# AUC values
auc_akaike <- as.numeric(auc(roc(data.val$Churn, predict(akaike.both, newdata = data.val, type = "response"))))
auc_bayesian <- as.numeric(auc(roc(data.val$Churn, predict(bayesian.both, newdata = data.val, type = "response"))))
auc_full <- as.numeric(auc(roc(data.val$Churn, baseline.pred)))
# comparison (for now) between full, aic, bic
akaike_df <- data.frame(Model = "Akaike",
Accuracy = akaike.metrics$Accuracy,
Precision = akaike.metrics$Precision,
Recall = akaike.metrics$Recall,
F1_Score = akaike.metrics$F1,
AUC = auc_akaike)
bayesian_df <- data.frame(Model = "Bayesian",
Accuracy = bayesian.metrics$Accuracy,
Precision = bayesian.metrics$Precision,
Recall = bayesian.metrics$Recall,
F1_Score = bayesian.metrics$F1,
AUC = auc_bayesian)
full_df <- data.frame(Model = "Full Logistic",
Accuracy = baseline.metrics$Accuracy,
Precision = baseline.metrics$Precision,
Recall = baseline.metrics$Recall,
F1_Score = baseline.metrics$F1,
AUC = auc_full)
comparison_df <- bind_rows(akaike_df, bayesian_df, full_df)
comparison_df
# LASSO
set.seed(1)
ctrl <- trainControl(method = "cv", number = 10)
lasso <- train(Churn ~ ., data = data.train.balanced, method = "glmnet", metric = "Accuracy", trControl = ctrl, tuneGrid = expand.grid(alpha = 1, lambda = seq(0, 0.15, length = 30)))
max(lasso$results$Accuracy)
lasso$bestTune
lasso.predict <- predict(lasso, data.val)
lasso.cm <- table(lasso.predict, data.val$Churn)
lasso.metrics <- get.metrics(lasso.cm)
lasso.plot <- lasso %>%
ggplot(aes(x = lambda, y = Accuracy)) +
geom_line() +
geom_point() +
geom_text(aes(label = sprintf("%.3f", Accuracy)), check_overlap = TRUE, vjust = -0.5, size = 2.5) +
scale_x_continuous(limits = c(0, 0.10)) +
labs(x = TeX("Lambda ($\\lambda$)"), y = "Accuracy", title = "Accuracy vs. Lambda for Lasso Regularization") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, face = "bold")
)
#RIDGE
set.seed(1)
ridge <- train(Churn ~ ., data = data.train.balanced, method = "glmnet", metric = "Accuracy", trControl = ctrl, tuneGrid = expand.grid(alpha = 0, lambda = seq(0, 0.15, length = 30)))
max(ridge$results$Accuracy)
ridge$bestTune
ridge.plot <- ridge %>%
ggplot(aes(x = lambda, y = Accuracy)) +
geom_line() +
geom_point() +
geom_text(aes(label = sprintf("%.3f", Accuracy)), check_overlap = TRUE, vjust = -0.5, size = 2.5) +
labs(x = TeX("Lambda ($\\lambda$)"), y = "Accuracy", title = "Accuracy vs. Lambda for Ridge Regularization") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, face = "bold")
)
ridge.predict <- predict(ridge, data.val)
ridge.cm <- table(ridge.predict, data.val$Churn)
ridge.metrics <- get.metrics(ridge.cm)
par(mfrow = c(1,2))
auc.lasso <- roc(data.val$Churn, as.numeric(lasso.predict),
plot = TRUE, main = "ROC Curve Lasso Model", col = "purple", lwd = 3,
auc.polygon = TRUE, print.auc = TRUE)
grid.arrange(lasso.plot, ridge.plot, top = "Penalized Approaches for Logistic Regression")
lasso_df <- data.frame(Model = "Logistic Lasso",
Accuracy = lasso.metrics$Accuracy,
Precision = lasso.metrics$Precision,
Recall = lasso.metrics$Recall,
F1_Score = lasso.metrics$F1,
AUC = as.numeric(auc.lasso$auc))
ridge_df <- data.frame(Model = "Logistic Ridge",
Accuracy = ridge.metrics$Accuracy,
Precision = ridge.metrics$Precision,
Recall = ridge.metrics$Recall,
F1_Score = ridge.metrics$F1,
AUC = as.numeric(auc.ridge$auc))
par(mfrow = c(1,2))
auc.lasso <- roc(data.val$Churn, as.numeric(lasso.predict),
plot = TRUE, main = "ROC Curve Lasso Model", col = "purple", lwd = 3,
auc.polygon = TRUE, print.auc = TRUE)
